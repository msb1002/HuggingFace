{"cells":[{"cell_type":"markdown","metadata":{"id":"A2Fq6cdPVyHZ"},"source":["#1. Library imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0cMTc_WZmJU"},"outputs":[],"source":["!pip install -q datasets transformers[sentencepiece]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2435,"status":"ok","timestamp":1648651956705,"user":{"displayName":"","userId":""},"user_tz":-480},"id":"Hmuquvg9Vxb8","outputId":"dd588516-7673-468d-834f-3c85876cdda2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648651956706,"user":{"displayName":"","userId":""},"user_tz":-480},"id":"vm01eqGpV1pG","outputId":"c115dfa1-28c1-4fa1-bf36-b2f48ed5bd0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":58}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import GridSearchCV\n","\n","import tqdm\n","import nltk\n","import torch\n","import numpy as np\n","import pandas as pd\n","from torch import nn\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.metrics import confusion_matrix, classification_report\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xc_diP9BH4rS"},"outputs":[],"source":["import transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9ZyjoH4bbnu"},"outputs":[],"source":["from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n","from transformers.modeling_outputs import TokenClassifierOutput\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","import tqdm\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"markdown","metadata":{"id":"A0JBZUtWWIah"},"source":["# 2. Data Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xN977AgdHyP1"},"outputs":[],"source":["def load_data(split_name='train', columns=['text', 'stars'], folder='gdrive/MyDrive/COMP_4332/Project1/data'):\n","        df = pd.read_csv(f'{folder}/{split_name}.csv')\n","        return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZnuCMsPWjuu"},"outputs":[],"source":["train_df = load_data('train', columns=['text', 'stars'])\n","valid_df = load_data('valid', columns=['text', 'stars'])\n","# the test set labels (the 'stars' column) are not available! So the following code will instead return all columns\n","test_df = load_data('test', columns=['text', 'stars'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648651957069,"user":{"displayName":"","userId":""},"user_tz":-480},"id":"0lZKxeS5ZDMQ","outputId":"03180683-d6a3-4073-93d7-090db9373154","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}],"source":["train_df = train_df[[\"text\",\"stars\"]]\n","train_df[\"stars\"] = train_df[\"stars\"]-1\n","valid_df = valid_df[[\"text\",\"stars\"]]\n","valid_df[\"stars\"] = valid_df[\"stars\"]-1"]},{"cell_type":"code","source":["import tempfile\n","import pathlib\n","import pyarrow as pa\n","import pyarrow.parquet as pq"],"metadata":{"id":"TT-YEHXILUzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swOKRRJqZmJV","executionInfo":{"status":"ok","timestamp":1648651980435,"user_tz":-480,"elapsed":23368,"user":{"displayName":"","userId":""}},"outputId":"7f2ed989-209e-4e38-c4e3-8c11f9027e4d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}],"source":["import datasets\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","\n","checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","def tokenize_function(x):\n","    return tokenizer(x, truncation=True)#return_tensors = 'pt'\n","\n","def tokenize_df(df):\n","  tokens = df['text'].map(tokenize_function)\n","  df['input_ids'] = [x['input_ids'] for x in tokens]\n","  df['attention_mask'] = [x['attention_mask'] for x in tokens]\n","  df['token_type_ids'] = [x['token_type_ids'] for x in tokens]\n","  df.rename(columns={\"stars\":\"labels\"},inplace=True)\n","  return df\n","\n","train_df = tokenize_df(train_df)\n","valid_df = tokenize_df(valid_df)\n","test_df = tokenize_df(test_df)\n","\n","small_train = train_df[:3000]\n","small_validate = valid_df[:1000]\n","\n","table_train = pa.table({'labels': (list(small_train[\"labels\"])), 'input_ids':list(small_train[\"input_ids\"]), 'attention_mask':list(small_train[\"attention_mask\"]),'token_type_ids':list(small_train[\"token_type_ids\"]) })\n","table_validate = pa.table({'labels': list(small_validate[\"labels\"]),'input_ids':list(small_validate[\"input_ids\"]), 'attention_mask':list(small_validate[\"attention_mask\"]),'token_type_ids':list(small_validate[\"token_type_ids\"])})\n","\n","#training = datasets.DatasetDict({\"labels\":list(train_df[\"labels\"]), \"text\": list(train_df[\"text\"])})\n","training = datasets.Dataset(table_train)\n","valid = datasets.Dataset(table_validate)\n","\n","MyDataset = datasets.DatasetDict({\"train\":training,\"validation\":valid})\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","source":["type(MyDataset['train'][0]['input_ids'])"],"metadata":{"id":"b_J6cFHPIQjX","executionInfo":{"status":"ok","timestamp":1648651980435,"user_tz":-480,"elapsed":15,"user":{"displayName":"","userId":""}},"outputId":"a18914be-8e31-4117-f19d-295f8ef40a5e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"TSoIpa2ZM7Co"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N932v6MMZmJV","executionInfo":{"status":"ok","timestamp":1648651980436,"user_tz":-480,"elapsed":8,"user":{"displayName":"","userId":""}},"outputId":"4bdaec88-0324-4071-a66d-fe9cd0f0ce36","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["from transformers import TrainingArguments\n","training_args = TrainingArguments(\"test-trainer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebjpKrdOZmJW","executionInfo":{"status":"ok","timestamp":1648651984308,"user_tz":-480,"elapsed":3877,"user":{"displayName":"","userId":""}},"outputId":"72c3a88e-132a-49ad-9d33-346b1e6dcbeb","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=5)"]},{"cell_type":"code","source":["type(MyDataset)"],"metadata":{"id":"jisYBRsBM_bL","executionInfo":{"status":"ok","timestamp":1648651984310,"user_tz":-480,"elapsed":26,"user":{"displayName":"","userId":""}},"outputId":"7632e0c8-b1f8-424c-fd6e-c8d2c5db87d9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["datasets.dataset_dict.DatasetDict"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["tokenized_datasets = MyDataset.with_format(\"torch\")"],"metadata":{"id":"c05K6HDQaQaA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tokenized_datasets"],"metadata":{"id":"mmbFZYtpdTVH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets[\"train\"][0]"],"metadata":{"id":"g5M_XrT4NLm9","executionInfo":{"status":"ok","timestamp":1648651984311,"user_tz":-480,"elapsed":21,"user":{"displayName":"","userId":""}},"outputId":"95a4cd40-02a2-4fa9-e5c8-eeb35aa8376c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'input_ids': tensor([  101,  1045,  1005,  2310,  2042,  2182,  1037,  9210,  1997,  2335,\n","          2085,  1998,  1045,  1005,  2310,  2196,  2042,  9364,  1012,  1996,\n","          2833,  2003,  2467,  2204,  1998,  1996, 14903,  2024,  4248,  1012,\n","          2061,  2521,  2026,  2048,  5440,  5167,  2024,  1996, 23582,  4887,\n","          3401, 15890,  2007,  2627,  6444,  2072,  1998,  1996, 23582,  4887,\n","          3401, 17798,  1012,  2130,  2004,  1045,  2828,  2023,  2026,  2677,\n","          2003, 25813,  1998,  1045,  2074,  2018,  1996, 23582,  4887,  3401,\n","         15890,  1012,  1996, 15890,  2015,  2024,  2092,  2589,  1998,  2145,\n","         28900,   999,  1045,  2467,  2681, 11812,  1998,  3407,  1012,  1996,\n","         15890,  2015,  2064,  2022,  1037,  2210,  2006,  1996, 26484,  2217,\n","          1010,  2342,  2048,  2030,  2093, 20619,  2015,  1012,  1045,  1005,\n","          2310,  2036,  2018,  2068,  2043,  2017,  2069,  2734,  2006, 20619,\n","          2000,  4550,  2039,  1012,  2593,  2126,  2009,  2001,  2145, 11937,\n","         21756,   999,  1045,  1005,  2310,  2464,  1037,  3232,  1997,  2111,\n","          2131, 16521,  2015,  1998,  2027,  2024,  4121,  1998,  2298,  2204,\n","          1012,  1996, 14903,  2031,  2467,  2042,  5379,  2130,  2043,  2009,\n","          2001,  2428,  5697,  1012,   102]),\n"," 'labels': tensor(4),\n"," 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["tokenized_datasets[\"train\"][0]"],"metadata":{"id":"Hstld-2DfNBl","executionInfo":{"status":"ok","timestamp":1648651984311,"user_tz":-480,"elapsed":19,"user":{"displayName":"","userId":""}},"outputId":"cc84bec1-53a7-47a6-a344-d0c1d131fd05","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'input_ids': tensor([  101,  1045,  1005,  2310,  2042,  2182,  1037,  9210,  1997,  2335,\n","          2085,  1998,  1045,  1005,  2310,  2196,  2042,  9364,  1012,  1996,\n","          2833,  2003,  2467,  2204,  1998,  1996, 14903,  2024,  4248,  1012,\n","          2061,  2521,  2026,  2048,  5440,  5167,  2024,  1996, 23582,  4887,\n","          3401, 15890,  2007,  2627,  6444,  2072,  1998,  1996, 23582,  4887,\n","          3401, 17798,  1012,  2130,  2004,  1045,  2828,  2023,  2026,  2677,\n","          2003, 25813,  1998,  1045,  2074,  2018,  1996, 23582,  4887,  3401,\n","         15890,  1012,  1996, 15890,  2015,  2024,  2092,  2589,  1998,  2145,\n","         28900,   999,  1045,  2467,  2681, 11812,  1998,  3407,  1012,  1996,\n","         15890,  2015,  2064,  2022,  1037,  2210,  2006,  1996, 26484,  2217,\n","          1010,  2342,  2048,  2030,  2093, 20619,  2015,  1012,  1045,  1005,\n","          2310,  2036,  2018,  2068,  2043,  2017,  2069,  2734,  2006, 20619,\n","          2000,  4550,  2039,  1012,  2593,  2126,  2009,  2001,  2145, 11937,\n","         21756,   999,  1045,  1005,  2310,  2464,  1037,  3232,  1997,  2111,\n","          2131, 16521,  2015,  1998,  2027,  2024,  4121,  1998,  2298,  2204,\n","          1012,  1996, 14903,  2031,  2467,  2042,  5379,  2130,  2043,  2009,\n","          2001,  2428,  5697,  1012,   102]),\n"," 'labels': tensor(4),\n"," 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cT0D1XTmZmJW"},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"mL_c3ySROHCD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2sAqy3MZmJX","executionInfo":{"status":"ok","timestamp":1648653120625,"user_tz":-480,"elapsed":1135656,"user":{"displayName":"","userId":""}},"outputId":"4a6b9156-11d8-4403-9d89-7bb304e62d05","colab":{"base_uri":"https://localhost:8080/","height":592}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 3000\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1125\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1125/1125 18:54, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.938600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.527100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to test-trainer/checkpoint-500\n","Configuration saved in test-trainer/checkpoint-500/config.json\n","Model weights saved in test-trainer/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in test-trainer/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in test-trainer/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to test-trainer/checkpoint-1000\n","Configuration saved in test-trainer/checkpoint-1000/config.json\n","Model weights saved in test-trainer/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in test-trainer/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in test-trainer/checkpoint-1000/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1125, training_loss=0.6962898457845053, metrics={'train_runtime': 1135.9666, 'train_samples_per_second': 7.923, 'train_steps_per_second': 0.99, 'total_flos': 1604083310647872.0, 'train_loss': 0.6962898457845053, 'epoch': 3.0})"]},"metadata":{},"execution_count":75}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vti_B-IiZmJX","executionInfo":{"status":"ok","timestamp":1648653165364,"user_tz":-480,"elapsed":44767,"user":{"displayName":"","userId":""}},"outputId":"2d3420a4-ce09-4b6b-eb4f-9dccaf0b2f3b","colab":{"base_uri":"https://localhost:8080/","height":106}},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 1000\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 00:44]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1000, 5) (1000,)\n"]}],"source":["predictions = trainer.predict(tokenized_datasets[\"validation\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXJGJNkcZmJY"},"outputs":[],"source":["preds = np.argmax(predictions.predictions, axis=-1)"]},{"cell_type":"code","source":["gt = np.array(valid_df[\"labels\"][:1000])"],"metadata":{"id":"LC97zS3nSCzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(gt)"],"metadata":{"id":"yzsYGXTYSzCr","executionInfo":{"status":"ok","timestamp":1648653165366,"user_tz":-480,"elapsed":25,"user":{"displayName":"","userId":""}},"outputId":"80a06ed6-3dab-41d7-a7cb-7f172d839f69","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["import sklearn\n","acc = sklearn.metrics.accuracy_score(gt,preds)"],"metadata":{"id":"qruogaipSCeW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"final validation accuracy \", acc)"],"metadata":{"id":"S9KcAkM4R9U9","executionInfo":{"status":"ok","timestamp":1648653165995,"user_tz":-480,"elapsed":21,"user":{"displayName":"","userId":""}},"outputId":"1c6a2737-d34c-4c18-f51c-0b6a6b9cbf73","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["final validation accuracy  0.663\n"]}]}],"metadata":{"colab":{"name":"Finetune_with_TrainerAPI.ipynb","provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb","timestamp":1648653226041}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}